{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qv8_Q9knv3om"
   },
   "source": [
    "### Codenation\n",
    "\n",
    "__Autor__: Kazuki Yokoyama (kazuki.yokoyama@ufrgs.br)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FC9NvpcO7XjW"
   },
   "source": [
    "# Pensamento estatístico em Python\n",
    "\n",
    "Neste módulo falaremos sobre testes de hipóteses.\n",
    "\n",
    "![hypthesis-testing](https://i1.wp.com/statisticsbyjim.com/wp-content/uploads/2018/07/TypesErrorHypothesisTests.png?resize=600%2C400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HK2aSUXU9I_s"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as sct\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsoiY5gw9KJ_"
   },
   "outputs": [],
   "source": [
    "# Algumas configurações para o matplotlib.\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "\n",
    "figsize(12, 8)\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9U2fS1OAKHCB"
   },
   "source": [
    "## Testes de hipóteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXgrQ3Ef9FJ5"
   },
   "source": [
    "### Introdução\n",
    "\n",
    "Já vimos antes como podemos fazer estimativas para parâmetros populacionais a partir de amostras da população. Agora veremos como testar hipóteses sobre parâmetros populacionais, incluindo sua distribuição. Testes de hipóteses são as principais ferramentas da inferência estatística para isso.\n",
    "\n",
    "Em um teste de hipóteses, formulamos duas hipóteses __complementares__ a respeito de um parâmetro populacional de interesse chamadas hipótese nula (_null hypothesis_) e hipótese alternativa (_alternative hypothesis_). Denotamos a hipótese nula por $H_{0}$ e a hipótese alternativa por $H_{1}$.\n",
    "\n",
    "__Exemplo__:\n",
    "\n",
    "Podemos estar interessados na média dos pesos de determinada população ($\\mu$) e queremos testar se seu valor verdadeiro é 70 kg a partir de uma amostra coletada. Para isso, geramos as seguintes hipóteses:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "  H_{0}: \\mu = 70 & \\quad \\text{(Hipótese nula)} \\\\\n",
    "  H_{1}: \\mu \\neq 70 & \\quad \\text{(Hipótese alternativa)}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Então seguimos um procedimento para avaliar se devemos:\n",
    "\n",
    "1. Rejeitar a hipótese nula em favor da hipótese alternativa. Nesse caso, diríamos que a verdadeira média populacional _não_ é 70 kg, mas não conseguiríamos afimar qual é o seu verdadadeiro valor.\n",
    "2. Não rejeitar a hipótese nula, mantendo-a. Nesse caso, diríamos que não temos evidências o suficiente para rejeitar a hipótese de que a verdadeira média populacional é 70 kg. No entanto, isso não significa que a média deva ser de fato 70 kg, mas sim que a nossa amostra parece sustentar essa ideia.\n",
    "\n",
    "> Apesar de comum, é incorreto dizer que \"aceitamos a hipótese nula\". Na verdade, simplesmente __não__ a rejeitamos por falta de evidências.\n",
    "\n",
    "Algumas observações sobre as hipóteses acima:\n",
    "\n",
    "* Notem como as duas hipóteses são complementares.\n",
    "* As hipóteses são feitas sobre o parâmetro populacional ($\\mu$) e não sobre o estimador amostral (que poderia ser $\\bar{X}$).\n",
    "* Só existem duas hipóteses. Não podemos gerar múltiplas hipóteses simultaneamente.\n",
    "* O resultado do teste não nos diz nada sobre nossa teoria, e sim sobre o que os dados indicam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixmJD-GOH3OX"
   },
   "source": [
    "### Funcionamento\n",
    "\n",
    "Para seguir com o nosso teste de hipóteses (TH), devemos coletar uma amostra da população e trabalhar com algum estimador do parâmetro populacional sob estudo. No caso acima, podemos utilizar a média amostral ($\\bar{X}$) que é o melhor estimador para a média populacional.\n",
    "\n",
    "Imagine que a média da amostral foi 74 kg. Note como isso pode ocorrer mesmo quando a verdadeira média populacional é 70 kg, pois a amostra é aleatória, e para cada amostra aleatória, obteríamos um valor diferente para a média.\n",
    "\n",
    "A questão é: essa diferença de 4 kg foi devido ao acaso (devido a aleatoriedade da amostra) ou porque a média populacional não é mesmo 70 kg (talvez 73 kg)? É para responder a esse tipo de questão que usamos o TH."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gh85LB7jKEWQ"
   },
   "source": [
    "__Todo procedimento de um TH é feito considerando a $H_{0}$ verdadeira__.\n",
    "\n",
    "Podemos considerar inicialmente que a verdadeira média populacional é de fato $\\mu = 70$ e que os pesos são normalmente distribuídos (depois veremos como relaxar essa suposição).\n",
    "\n",
    "Sendo isso verdade, as médias de pesos das amostras devem se distribuir normalmente em torno de 70 kg. O que devemos então fazer é definir uma região onde ainda consideramos aceitável presumir que a verdadeira média é 70 kg. Tudo que estiver fora dessa região é considerado \"muito longe\" para que a verdadeira média seja 70 kg.\n",
    "\n",
    "A primeira região (a que sustenta a hipótese da média real 70 kg) é chamada __região de aceitação__ (RA), e tudo que estiver fora dela é chamado __região crítica__ (RC).\n",
    "\n",
    "Por exemplo, podemos definir RA como sendo o intervalo de 68 kg a 72 kg, ou seja, consideramos que qualquer diferença de 2kg ou menos de 70 kg é devido ao acaso. Qualquer valor fora desse intervalo já é longe demais de 70 kg para que esta seja a verdadeira média. Nesse cenário, a nossa média amostral de 74 kg cai na RC e portanto rejeitaríamos a hipótese nula.\n",
    "\n",
    "O que precisamos agora é de um meio formal de definir essas regiões. Para isso, utilizaremos a informação de que, sob a hipótese nula, a média amostral $\\bar{X}$ tem distribuição normal em torno de $\\mu = 70$. E em vez de definirmos o tamanho da região de aceitação, definimos o tamanho da região crítica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQigeNcbTF9u"
   },
   "source": [
    "Todo TH conta com uma estatística de teste (vamos chamá-la de $T$), que é gerada a partir da amostra. A partir dessa estatística de teste e de sua distribuição, podemos definir RA e RC em termos de probabilidade.\n",
    "\n",
    "Por exemplo, podemos construir essas regiões de forma que, se $H_{0}$ for verdadeira, então $T$ tem 5% de probabilidade de cair na RC. Essa probabilidade de cair na região crítica, sendo $H_{0}$ verdadeira, é uma probabilidade de erro. Esse erro é chamado de Erro Tipo I e sua probabilidade é chamada __nível de significância__ e denotada por $\\alpha$.\n",
    "\n",
    "Podemos cometer outro tipo de erro ao não rejeitarmos $H_{0}$ quando ela é realmente falsa. Esse é o Erro Tipo II e sua probabilidade é denotada por $\\beta$.\n",
    "\n",
    "Em resumo:\n",
    "\n",
    "$$\\alpha = P(\\text{Erro Tipo I}) = P(\\text{rejeitar } H_{0} | H_{0} \\text{ verdadeira})$$\n",
    "$$\\beta = P(\\text{Erro Tipo II}) = P(\\text{não rejeitar } H_{0} | H_{0} \\text{ falsa})$$\n",
    "\n",
    "> $\\alpha$ e $\\beta$ não possuem relação matemática.\n",
    "\n",
    "__Quando criamos um TH, devemos decidir *a priori* o valor de $\\alpha$__. Ele será nossa base de comparação para rejeitarmos ou não a $H_{0}$. Não fazer isso é chamado _p-value hacking_.\n",
    "\n",
    "Valores típicos de $\\alpha$ são 0.025, 0.05 e 0.10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ttPP2_m7gBzX"
   },
   "source": [
    "### Classificação do teste de hipóteses\n",
    "\n",
    "Os TH podem ser classificados em:\n",
    "\n",
    "* Bilaterais: quando a região crítica encontra-se dos dois lados da distribuição de $T$ sob $H_{0}$.\n",
    "* Unilaterais: quando a região crítica encontra-se somente de um dos lados da distribuição de $T$ sob $H_{0}$.\n",
    "\n",
    "Quando o TH é bilateral, a probabilidade $\\alpha$ geralmente é dividida em duas partes iguais, uma em cada lado da distribuição. Quando o TH é unilateral, toda probabilidade acumula-se em um dos lados.\n",
    "\n",
    "Também podemos falar em hipóteses alternativas simples e compostas:\n",
    "\n",
    "* Simples: quando não desigualdade.\n",
    "* Composta: quando há desigualdade.\n",
    "\n",
    "Na figura a seguir, consideramos que $H_{0}: \\mu = \\mu_{0}$ e mostramos o caso bilateral e dois unilaterais:\n",
    "\n",
    "![hypothesis-testing](https://cdn-images-1.medium.com/max/1200/1*-aqjLkyD-mXsA2Hxa8cKSg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZAHGAvvWJJx"
   },
   "source": [
    "### Valor-p\n",
    "\n",
    "O valor-p (do Inglês, _p-value_), também chamado de _nível descritivo_, de um TH é um valor associado ao resultado, $t^{*}$, da estatística de teste $T$ sob $H_{0}$.\n",
    "\n",
    "__O valor-p é a probabilidade de $T$ tomar um valor igual ou mais extremo que $t^{*}$, sendo $H_{0}$ verdadeira__.\n",
    "\n",
    "Obviamente, se essa probabilidade for muito baixa, podemos interpretar que é muito raro encontrarmos $t^{*}$ se $H_{0}$ for realmente verdadeira. Por outro lado, se ela for alta, podemos concluir que deve ser razoável encontrarmos esse valor de $t^{*}$ quando $H_{0}$ é verdadeira.\n",
    "\n",
    "Mas qual o limiar? O que é considerada uma probabilidade baixa ou alta? É aí que entra o $\\alpha$ novamente!\n",
    "\n",
    "O nosso limiar é o valor de $\\alpha$ estabelecido:\n",
    "\n",
    "* Se o valor-p for menor que $\\alpha$, então $t^{*}$ caiu dentro da região crítica, e portanto devemos rejeitar $H_{0}$.\n",
    "* Se o valor-p for maior que $\\alpha$, então $t^{*}$ caiu na região de aceitação e devemos não rejeitar $H_{0}$.\n",
    "\n",
    "Essa é a importância de estabelecermos $\\alpha$ antes do experimento. Do contrário, poderíamos ajustar o valor de $\\alpha$ para atender nossas expectativas sobre o resultado.\n",
    "\n",
    "É importante notar que o valor-p faz sentido no contexto da estatística frequentista, ou seja, considerando a probabilidade no \"longo prazo\". Além disso, ele nada nos afirma sobre a teoria sendo testada, apenas o que os dados dizem.\n",
    "\n",
    "Também temos outra interpretação para o valor-p: __O valor-p é o menor nível de significância, $\\alpha$, para o qual rejeitaríamos $H_{0}$__.\n",
    "\n",
    "![p-value](https://i.stack.imgur.com/idDTA.png)\n",
    "\n",
    "É importante notar que o valor-p é usado extensivamente na estatística frequentista, mas a estatística Bayesiana possui outra abordagem que dispensa o valor-p.\n",
    "\n",
    "O valor-p é considerado perigoso, pois muitas pessoas não sabem utilizá-lo adequadamente, nem interpretá-lo corretamente, levando a uma série de conclusões duvidosas.\n",
    "\n",
    "__Lembre-se: o valor-p nos permite fazer afimarções sobre os dados, não sobre a teoria sendo testada__.\n",
    "\n",
    "Mas como o próprio valor-p se distribui?\n",
    "\n",
    "De forma geral:\n",
    "\n",
    "* Quando $H_{0}$ é realmente falsa, a distribuição do valor-p depende do poder do teste, ou seja, da capacidade do teste de detectar uma $H_{0}$ falsa. Quanto maior o poder do teste, maior a chance de obtermos um $\\alpha$ pequeno ($< 0.05$).\n",
    "\n",
    "![1](https://drive.google.com/uc?export=download&id=12Z1cB5T9P2kMp7PXB_xuHitaKwcxbrKF)\n",
    "\n",
    "* Quando $H_{0}$ é realmente verdadeira, o valor-p tem distribuição uniforme, com $100\\alpha\\%$ dos valores-p sendo menores que $\\alpha$. Em outras palavras, temos $100\\alpha\\%$ de chance de cometermos um Erro Tipo I.\n",
    "\n",
    "![2](https://drive.google.com/uc?export=download&id=1PD-1URs2FzaHEF1ZLV2Ajlb0tvY0OXcU)\n",
    "\n",
    "Vamos fazer simulações de Monte-Carlo para mostrar isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "colab_type": "code",
    "id": "reI10ijK_yEc",
    "outputId": "151a3018-2486-49dd-ff4d-0ea90588aaf4"
   },
   "outputs": [],
   "source": [
    "# H_0 é falsa.\n",
    "\n",
    "pvalues1 = []\n",
    "for i in range(1000):\n",
    "  pvalues1.append(sct.ttest_1samp(sct.norm.rvs(loc=10, scale=5, size=100), popmean=12).pvalue) # Menor poder.\n",
    "\n",
    "pvalues2 = []\n",
    "for i in range(1000):\n",
    "  pvalues2.append(sct.ttest_1samp(sct.norm.rvs(loc=10, scale=5, size=100), popmean=8).pvalue) # Maior poder.\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "sns.distplot(pvalues1, kde=False, bins=20, hist_kws={\"density\": True}, ax=axs[0])\n",
    "sns.distplot(pvalues2, kde=False, bins=20, hist_kws={\"density\": True}, ax=axs[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "colab_type": "code",
    "id": "W4q6OtvwCHnT",
    "outputId": "14fb01f3-7288-4ba8-8f1b-26edb91e8d72"
   },
   "outputs": [],
   "source": [
    "# H_0 é verdadeira.\n",
    "\n",
    "pvalues = []\n",
    "for i in range(1000):\n",
    "  pvalues.append(sct.ttest_1samp(sct.norm.rvs(loc=10, scale=5, size=100), popmean=10).pvalue)\n",
    "\n",
    "\n",
    "sns.distplot(pvalues, kde=False, bins=20, hist_kws={\"density\": True});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AdvPFicghiVP"
   },
   "source": [
    "### Poder\n",
    "\n",
    "Definimos o poder de um teste como a probabilidade de rejeitarmos $H_{0}$ quando $H_{0}$ é realmente falsa. Em outras palavras, o poder é a probabilidade de não cometermos um Erro Tipo II:\n",
    "\n",
    "$$\\text{Poder} = \\pi(\\mu) = P(\\text{rejeitar } H_{0} | H_{0} \\text{ falsa}) = 1 - \\beta$$\n",
    "\n",
    "O poder é bastante influenciado pelo tamanho da amostra, então cuidado com interpretações sobre ele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJWHMRWjOGfQ"
   },
   "source": [
    "## _Q-Q plot_\n",
    "\n",
    "O _q-q plot_ é um gráfico para comparação de distribuições de probabilidades. Geralmente, uma das distribuições é teórica e com distribuição bem conhecida. Essa distribuição teórica é convencionalmente posta no eixo x. No eixo y, colocamos os quantis da nossa distribuição amostral, que gostaríamos de comparar com a teórica.\n",
    "\n",
    "![qq-plot](https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Normal_normal_qq.svg/686px-Normal_normal_qq.svg.png)\n",
    "\n",
    "Para o caso mais comum onde em y temos a amostra e em x temos a distribuição teórica com a qual queremos comparar, podemos pensar da seguinte forma:\n",
    "\n",
    "Sendo a amostra $S = \\{s_{1}, s_{2}, \\dots, s_{n}\\}$, um ponto $(x, y)$ de um _q-q plot_ é tal que:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "  x = F^{-1}(G(s)) \\\\\n",
    "  y = s\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "sendo $F^{-1}$ a função quantil (inversa da CDF) da distribuição teórica, $G$ a CDF empírica da amostra e $s = s_{1}, s_{2}, \\dots, s_{n}$.\n",
    "\n",
    "De qualquer forma, a cada ponto $(x_{i}, y_{i})$ do _q-q plot_  vale a relação $F(x_{i}) = G(y_{i})$.\n",
    "\n",
    "Se as duas distribuições a serem comparadas são de amostras, o raciocínio permanece muito parecido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utv4UirwXWjS"
   },
   "source": [
    "Se as duas distribuições forem iguais, ou seja, $F = G$, então os pontos ficarão em cima da reta $y = x$ (inclinada 45º). Quanto mais alinhados os pontos estiverem em cima dessa reta, mais a distribuição da amostra se aproxima da distribuição teórica. Se os pontos ficarem em cima de uma outra reta, mas alinhados, pode ser que as distribuições estejam somente fora de escala. Nesse caso, pode ser interessante transformar uma das distribuições, por exemplo, padronizando a amostra (para ter média 0 e variância 1).\n",
    "\n",
    "O _q-q plot_ é uma boa forma gráfica de sabermos se as duas distribuições são iguais ou parecidas. A sua intuição é também utilizada em alguns testes de hipóteses para aderência à distribuições teóricas como o teste de normalidade de Jarque-Bera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LS4avxFK02T"
   },
   "source": [
    "__Q-Q plot para dados normais__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "id": "JZq5F2apKXeC",
    "outputId": "be32059e-b508-4475-d913-6d3f45012856"
   },
   "outputs": [],
   "source": [
    "normal_data = sct.norm.rvs(loc=10, scale=4, size=1000)\n",
    "\n",
    "sm.qqplot(normal_data, fit=True, line=\"45\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xp0bvdpfLJF3"
   },
   "source": [
    "__Q-Q plot para dados não normais__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "id": "scSaAzuqLMhH",
    "outputId": "f9f8d593-b171-4cb2-9d21-8b08448d94de"
   },
   "outputs": [],
   "source": [
    "non_normal_data = sct.expon.rvs(size=1000)\n",
    "\n",
    "sm.qqplot(non_normal_data, fit=True, line=\"45\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6mP3jQoZK0z"
   },
   "source": [
    "## Testes de hipóteses clássicos\n",
    "\n",
    "Diversos testes de hipóteses  para uma gama de tarefas já foram desenvolvidos pela comunidade estatística. Por ora, nosso trabalho é somente entender e saber aplicar os mais usuais. A teoria formal sobre a construção de TH pode ser encontrada facilmente em qualquer literatura sobre inferência estatística.\n",
    "\n",
    "Dois tipos bem comuns de TH são os testes de comparação e os testes de aderência (_goodness-of-fit_). Veremos aqui dois testes para comparação de médias e dois testes de normalidade: Shapiro-Wilk e Jarque-Bera.\n",
    "\n",
    "Antes de prosseguirmos, um aviso por Neyman e Pearson:\n",
    "\n",
    "> _Statistical tests should be used with discretion and understanding, and not as instruments which themeselves give the final verdict_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bs8KSKJsg2zE"
   },
   "source": [
    "### Teste de média de uma amostra\n",
    "\n",
    "O teste de hipóteses mais conhecido certamente é sobre a média de uma amostra: o famoso teste-$t$ da média.\n",
    "\n",
    "Nosso objetivo com esse teste é avaliar se uma dada amostra $S$ foi coletada de uma distribuição cuja média $\\mu$ é igual a $\\mu_{0}$.\n",
    "\n",
    "Podemos formular nossas hipóteses da seguinte forma:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "  H_{0}: \\mu = \\mu_{0} \\\\\n",
    "  H_{1}: \\mu \\neq \\mu_{0}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Partimos de uma suposição inicial: nossa distribuição original é normal sob $H_{0}$ (depois veremos que é possível relaxar isso).\n",
    "\n",
    "A partir dessa suposição, podemos afimar que nossa média amostral $\\bar{X}$ também tem distribuição simétrica de média $\\mu_{0}$ e desvio-padrão $s/\\sqrt{n}$, chamado erro-padrão.\n",
    "\n",
    "Para construir nossa estatística de teste $t$, fazemos:\n",
    "\n",
    "$$t = \\frac{\\bar{x} - \\mu_{0}}{s/\\sqrt{n}}$$\n",
    "\n",
    "onde $\\bar{x}$ é a média obtida a partir da amostra, $s$ é o desvio-padrão calculado a partir da amostra e $n$ é o tamanho da amostra.\n",
    "\n",
    "Essa estatística $t$ tem distribuição $t$-Student com $n-1$ graus de liberdade, que é bem próxima da distribuição normal. Ela é utilizada em vez da normal, pois suas caudas mais pesadas compensam a aproximação feita de $s$ para o desvio padrão.\n",
    "\n",
    "Como sempre devemos estabelecer _a priori_ o valor de $\\alpha$, nosso nível de significância, a fim de compararmos com valor numérico obtido de $t$. Se $t$ cair na região de aceitação (que depende de $\\alpha$), então não rejeitamos a hipótese de que a verdadeira média é $\\mu_{0}$. Do contrário, podemos dizer que temos evidências o suficiente para rejeitar tal hipótese, e portanto $\\mu$ não deve ser igual a $\\mu_{0}$.\n",
    "\n",
    "Para relaxar a suposição de distribuição normal dos dados, apelamos para o Teorema Central do Limite (TCL) que nos afirma que:\n",
    "\n",
    "$$\\bar{X} \\xrightarrow{d} N(\\mu, \\frac{\\sigma^{2}}{n})$$\n",
    "\n",
    "quando $n \\rightarrow \\infty$.\n",
    "\n",
    "Ou seja, se tivermos uma amostra grande o suficiente, podemos usar o TCL para justificar os cálculos anteriores, incluindo a fórmula da estatística de teste $t$, sem precisar presumir normalidade dos dados.\n",
    "\n",
    "Para isso, sob $H_{0}$, substituímos $\\mu$ por $\\mu_{0}$ e estimamos $\\sigma$ como $s$ (desvio-padrão amostral), chegando à mesma fórmula de $t$. Além disso, a distribuição $t$-Student se aproxima de uma distribuição normal quando $n \\rightarrow \\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c20v0EEuMsdl",
    "outputId": "d2c9298e-5676-4409-f887-642bcc5dcd9f"
   },
   "outputs": [],
   "source": [
    "data = sct.expon.rvs(scale=10, size=1000) # Mean = scale = 1/lambda = 10.\n",
    "\n",
    "sct.ttest_1samp(data, popmean=10) # Deveria não rejeitar H_0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ln4Z3Iy3OlpI",
    "outputId": "6f01f421-3ba0-460a-e197-30bdba035b6e"
   },
   "outputs": [],
   "source": [
    "data = sct.expon.rvs(scale=8, size=1000) # Mean = scale = 1/lambda = 8.\n",
    "\n",
    "sct.ttest_1samp(data, popmean=10) # Deveria rejeitar H_0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_fccwEBlvHZ"
   },
   "source": [
    "### Teste de comparação das médias de duas amostras\n",
    "\n",
    "Outro cenário bastante comum é querermos comparar as médias de duas amostras diferentes para descobrirmos se as duas amostras vêm de distribuições de mesma média.\n",
    "\n",
    "Entendido o teste anterior, o racional do presente teste é bem direto: usamos a diferença entre as duas médias amostrais e os respectivos desvios-padrão no cálculo da estatística de teste $t$. Ou seja,\n",
    "\n",
    "$$t = \\frac{\\bar{x}_{1} - \\bar{x}_{2}}{\\sqrt{s_{1}^{2} + s_{2}^{2}}}$$\n",
    "\n",
    "onde $\\bar{x}_{1}$ e $\\bar{x}_{2}$ são as médias da primeira e segunda amostras e $s_{1}$ e $s_{2}$ são os desvios-padrão das duas amostras.\n",
    "\n",
    "Sob $H_{0}$, é possível mostrar que $t$ tem distribuição $t$-Student com $n_{1} + n_{2} - 2$ graus de liberdade, onde $n_{1}$ e $n_{2}$ são os tamanhos das amostras.\n",
    "\n",
    "A interpretação do resultado de $t$ com relação ao nível de significância e consequente rejeição (ou não) de $H_{0}$ é análoga ao teste anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fr4Y2bzdMLVD",
    "outputId": "aa85e2b2-3ba8-4561-90ad-36a97f046417"
   },
   "outputs": [],
   "source": [
    "data_one = sct.expon.rvs(scale=8, size=100) # Mesmas distribuições.\n",
    "data_two = sct.expon.rvs(scale=8, size=100)\n",
    "\n",
    "sct.ttest_ind(data_one, data_two) # Não deveria rejeitar H_0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ejx3ybHxPU7w",
    "outputId": "002b27e6-bc86-4fba-8b4b-8cf9d8ab2566"
   },
   "outputs": [],
   "source": [
    "data_one = sct.expon.rvs(scale=8, size=100) # Distribuições diferentes.\n",
    "data_two = sct.expon.rvs(scale=12, size=100)\n",
    "\n",
    "sct.ttest_ind(data_one, data_two) # Deveria rejeitar H_0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C2Xf3GlJsDbp"
   },
   "source": [
    "### Shapiro-Wilk\n",
    "\n",
    "O teste de Shapiro-Wilk é um teste de aderência à distribuição normal, que abreviamos para teste de normalidade. Nosso intuito é verificar se uma dada amostra veio ou não de uma distribuição normal.\n",
    "\n",
    "Não precisamos e não entraremos nos detalhes da sua estatística de teste. Tudo que precisamos saber por ora é:\n",
    "\n",
    "* A hipótese nula, $H_{0}$, é a normalidade dos dados.\n",
    "  * Se o valor-p for menor que o nível de significância $\\alpha$, então temos evidências de que os dados não vêm de uma distribuição normal.\n",
    "  * Se o valor-p for maior que $\\alpha$, então não podemos afimar que os dados não vêm de uma distribuição normal (o que é sutilmente diferente de afirmar que eles _vêm_ de uma distribuição normal. Cuidado!).\n",
    "* Apesar de ter tendência a melhores resultados quanto maior a amostra, a maior parte das implementações não suporta computações com amostras muito grandes.\n",
    "  * A implementação do SciPy por exemplo só suporta até 5000 observações.\n",
    "* É altamente aconselhado fazer o teste em conjunto com uma análise gráfica de um _q-q plot_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EG-ltCuQPc1W",
    "outputId": "32ec836d-404e-4b98-cc65-459add84f44d"
   },
   "outputs": [],
   "source": [
    "normal_data = sct.norm.rvs(loc=10, scale=4, size=100)\n",
    "\n",
    "sct.shapiro(normal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8tvWUYX4Przx",
    "outputId": "83e01ed0-78b9-420b-8572-7d37db3026b3"
   },
   "outputs": [],
   "source": [
    "normal_data = sct.expon.rvs(scale=4, size=100)\n",
    "\n",
    "sct.shapiro(normal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adIEM13XuRlN"
   },
   "source": [
    "### Jarque-Bera\n",
    "\n",
    "Assim como Shapiro-Wilk, o teste de Jarque-Bera é um teste de aderência à distribuição normal com $H_{0}$ sendo a normalidade dos dados. A diferença reside na estatística de teste utilizada.\n",
    "\n",
    "A estatística de teste é baseada na assimetria (_skewness_) e curtose (_kurtosis_) excessiva da amostra. Se a amostra vem de uma distribuição normal, então esses valores devem ser muito próximos de zero. Se isso acontecer, então a estatística de teste tem distribuição $\\chi^{2}$ com dois graus de liberdade.\n",
    "\n",
    "No entanto, se a amostra for pequena, podemos ter muitos falsos negativos (Erro Tipo I) ao utilizarmos a distribuição $\\chi^{2}$, ou seja, rejeitamos $H_{0}$ quando ela é verdadeira.\n",
    "\n",
    "Para evitar isso, as implementações costumam utilizar aproximações por Monte-Carlo quando $n$ é pequeno, reservando a aproximação $\\chi^{2}$ para amostras grandes.\n",
    "\n",
    "Novamente, é altamente aconselhado complementar o resultado desse teste com um _q-q plot_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LcUvjC4APy5D",
    "outputId": "117aa7b6-c8c0-475d-ff72-ef93ea386b1d"
   },
   "outputs": [],
   "source": [
    "normal_data = sct.norm.rvs(loc=10, scale=4, size=100)\n",
    "\n",
    "sct.jarque_bera(normal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xzU7eZBqP4Jj",
    "outputId": "da5fbf20-db39-419d-a8cc-118e666be6ca"
   },
   "outputs": [],
   "source": [
    "normal_data = sct.expon.rvs(scale=4, size=100)\n",
    "\n",
    "sct.jarque_bera(normal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDpdgnjvwFD7"
   },
   "source": [
    "## Referências\n",
    "\n",
    "* [A Gentle Introduction to Statistical Hypothesis Testing](https://machinelearningmastery.com/statistical-hypothesis-tests/)\n",
    "\n",
    "* [How to Correctly Interpret P Values](https://blog.minitab.com/blog/adventures-in-statistics-2/how-to-correctly-interpret-p-values)\n",
    "\n",
    "* [A Dirty Dozen: Twelve P-Value Misconceptions](http://www.perfendo.org/docs/BayesProbability/twelvePvaluemisconceptions.pdf)\n",
    "\n",
    "* [An investigation of the false discovery rate and the misinterpretation of p-values](https://royalsocietypublishing.org/doi/pdf/10.1098/rsos.140216)\n",
    "\n",
    "* [Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations](https://link.springer.com/content/pdf/10.1007%2Fs10654-016-0149-3.pdf)\n",
    "\n",
    "* [Why Are P Values Misinterpreted So Frequently?](https://statisticsbyjim.com/hypothesis-testing/p-values-misinterpreted/)\n",
    "\n",
    "* [Statistical Significance Explained](https://towardsdatascience.com/statistical-significance-hypothesis-testing-the-normal-curve-and-p-values-93274fa32687)\n",
    "\n",
    "* [Definition of Power](https://newonlinecourses.science.psu.edu/stat414/node/304/)\n",
    "\n",
    "* [The Math Behind A/B Testing with Example Python Code](https://towardsdatascience.com/the-math-behind-a-b-testing-with-example-code-part-1-of-2-7be752e1d06f)\n",
    "\n",
    "* [Handy Functions for A/B Testing in Python](https://medium.com/@henryfeng/handy-functions-for-a-b-testing-in-python-f6fdff892a90)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Aula 5 - Pensamento estatístico em Python.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
